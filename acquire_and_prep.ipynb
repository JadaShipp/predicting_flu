{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Modeling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "#Set figure size and figure size for all plots\n",
    "plt.rc(\"figure\", figsize = (16,16))\n",
    "plt.rc(\"font\", size=14)\n",
    "\n",
    "# Allow all columns to be displayed\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to use features captured from survey data to predict how likely individuals are to receive their H1N1 and seasonal flu vaccines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, I will be predicting two probabilities:\n",
    "- h1n1_vaccine - Whether respondent received H1N1 flu vaccine.\n",
    "- seasonal_vaccine - Whether respondent received seasonal flu vaccine.\n",
    "> Both are binary variables: 0 = No; 1 = Yes. Some respondents didn't get either vaccine, others got only one, and some got both. This is formulated as a multilabel (and not multiclass) problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Aquisition\n",
    "  * Download data into local drive\n",
    "2. Prepare\n",
    "  * Read in data csv using pandas\n",
    "  * Chekck data types and null values\n",
    "  * Fill in nulls\n",
    "  * Encode appropriately\n",
    "  * Scale if needed\n",
    "3. Explore\n",
    "4. Modeling\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I downloaded the data from https://www.drivendata.org/competitions/66/flu-shot-learning/data/ into the same file where this analysis is being conducted\n",
    "- Now I'll turn both the feature csv and the target variable csv data into a pandas dataframes for analysis and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the training set feature csv using pandas\n",
    "df = pd.read_csv('Flu_Shot_Learning_Predict_H1N1_and_Seasonal_Flu_Vaccines_-_Training_Features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable_df = pd.read_csv('Flu_Shot_Learning_Predict_H1N1_and_Seasonal_Flu_Vaccines_-_Training_Labels.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The target variable csv will need to be concatenated onto the feature csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, target_variable_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns = 'respondent_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify it was added correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The initial datatframe has:\n",
    "- 26,707 rows where each row is one person\n",
    "- 35 columns where each column is a feature this person has indicated on their survey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more info about the datframe. We'll use .info() to see how many non-null values we have in each column and what the data types are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial thoughts for cleaning/prep\n",
    "1. Several columns will need to be one hot encoded or label encoded\n",
    "2. Nans in several columns needs to be handled\n",
    "3. May need to drop certain columns\n",
    "4. All the datatypes seem to be appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by splitting the data into train and test to avoid exploring the test data which is meant to stay unseen. Then I'll perform the same clean and prep changes to each dataframe sequentially.\n",
    "> There's enough data here to split this further into train and validate sets which will help to prevent overfitting by allowing signs of overfitting to be caught before applying the model to the test data. After the appropriate cleaning and preparation are complete, I will create a validate set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll check to see which columns have nans, how many there are, and explore the best ways to fill those nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a for loop to determine what percentage of each column are nans\n",
    "def percent_nans(df):\n",
    "    x = ['column','n_nans', 'percentage_nans']\n",
    "    missing_data_df = pd.DataFrame(columns=x)\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        column_name = col\n",
    "        missing_data = df[col].isnull().sum()\n",
    "        missing_in_percentage = (df[col].isnull().sum()/df[col].shape[0])*100\n",
    "        \n",
    "        missing_data_df.loc[len(missing_data_df)] = [column_name, missing_data, missing_in_percentage]\n",
    "    return missing_data_df.sort_values(by = 'percentage_nans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_nans(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like only three columns have a significant number of values missing:\n",
    "  - __health_insurance__\n",
    "  - __employment_industry__\n",
    "  - __employment_occupation__\n",
    "- Look at the most common values in each feature and decide if there is a reasonable way to fill the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the most common health insurance?\n",
    "df.health_insurance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the most common employment_industry?\n",
    "df.employment_industry.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the most common employment occupation?\n",
    "df.employment_occupation.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that __employment_industry__ and __employment_occupation__ do not have a single most overwhelming industry or occupation that could be reasonably used to fill in the remaining half empty values. I will drop these columns and not include them in the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, __health_insurance__ has 12,697 observation recoded as having insurance of the total 14,433 observations with values recorded. It may be reasonable to simply fill in the remaining 45% missing values with the label for having insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I need to split the data into train and test. I think it would be better for exploring and modeling purposes to have a train and test dataframe for each target variable. After the predictions are made, I will concat the dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.seasonal_vaccine.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two dataframes each with only one of the target variables\n",
    "h1n1_df = df.drop(columns = 'seasonal_vaccine')\n",
    "\n",
    "seasonal_df = df.drop(columns = 'h1n1_vaccine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the train test split function from Sklearn and add a random seed for reproducibility\n",
    "# Use Stratify y parameter to ensure the same proportion of the y variable in both train and test dfs\n",
    "h1n1_train, h1n1_test = train_test_split(h1n1_df, random_state=123, train_size=.80, stratify=h1n1_df.h1n1_vaccine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the train test split function from Sklearn and add a random seed for reproducibility\n",
    "# Stratify y parameter to ensure the same proportion of the y variable in both train and testt dfs\n",
    "seasonal_train, seasonal_test = train_test_split(seasonal_df, random_state=123, train_size=.80, stratify=seasonal_df.seasonal_vaccine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the employment_industry and employment_occupation columns from dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train = h1n1_train.drop(columns =['employment_industry', 'employment_occupation'] )\n",
    "h1n1_test = h1n1_test.drop(columns =['employment_industry', 'employment_occupation'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure the columns were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train = seasonal_train.drop(columns =['employment_industry', 'employment_occupation'] )\n",
    "seasonal_test = seasonal_test.drop(columns =['employment_industry', 'employment_occupation'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the columns were dropped appropriately. Now let's fill in null values in the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to fill in the null values with the most common occurence\n",
    "def fill_null_values(train, test):\n",
    "    train = train.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "    test = test.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train, h1n1_test = fill_null_values(h1n1_train, h1n1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that there are no more null values in either dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train, seasonal_test = fill_null_values(seasonal_train, seasonal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to encode the columns that have objects as values and turn them into integer representations for the purpose of the classification model to predict how likely people are to get their flu vaccines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at which columns need to be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label_encode_columns(train, test):\n",
    "\n",
    "#     encoder = LabelEncoder()\n",
    "   \n",
    "#     encode_list = ['rent_or_own', 'employment_status', 'marital_status', 'sex']\n",
    "    \n",
    "             \n",
    "#     for column in encode_list:\n",
    "#         train[column] = encoder.fit_transform(train[column])\n",
    "#         test[column] = encoder.transform(test[column])\n",
    "\n",
    "#         return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = label_encode_columns(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_columns(h1n1_train, h1n1_test, seasonal_train, seasonal_test):\n",
    "    '''\n",
    "    Takes in train and test dataframes and label encodes columns.\n",
    "    Returns train and test dataframes with new columns label encoded.\n",
    "    '''\n",
    "    # Create the encoder object\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # Add a new column to the dataframe that is the column you want, label encoded\n",
    "    h1n1_train['encoded_employment_status'] = encoder.fit_transform(h1n1_train['employment_status'])\n",
    "    h1n1_train['encoded_rent_or_own'] = encoder.fit_transform(h1n1_train['rent_or_own'])\n",
    "    h1n1_train['encoded_marital_status'] = encoder.fit_transform(h1n1_train['marital_status'])\n",
    "    h1n1_train['encoded_sex'] = encoder.fit_transform(h1n1_train['sex'])\n",
    "\n",
    "    h1n1_test['encoded_employment_status'] = encoder.fit_transform(h1n1_test['employment_status'])\n",
    "    h1n1_test['encoded_rent_or_own'] = encoder.fit_transform(h1n1_test['rent_or_own'])\n",
    "    h1n1_test['encoded_marital_status'] = encoder.fit_transform(h1n1_test['marital_status'])\n",
    "    h1n1_test['encoded_sex'] = encoder.fit_transform(h1n1_test['sex'])\n",
    "\n",
    "    seasonal_train['encoded_employment_status'] = encoder.fit_transform(seasonal_train['employment_status'])\n",
    "    seasonal_train['encoded_rent_or_own'] = encoder.fit_transform(seasonal_train['rent_or_own'])\n",
    "    seasonal_train['encoded_marital_status'] = encoder.fit_transform(seasonal_train['marital_status'])\n",
    "    seasonal_train['encoded_sex'] = encoder.fit_transform(seasonal_train['sex'])\n",
    "\n",
    "    seasonal_test['encoded_employment_status'] = encoder.fit_transform(seasonal_test['employment_status'])\n",
    "    seasonal_test['encoded_rent_or_own'] = encoder.fit_transform(seasonal_test['rent_or_own'])\n",
    "    seasonal_test['encoded_marital_status'] = encoder.fit_transform(seasonal_test['marital_status'])\n",
    "    seasonal_test['encoded_sex'] = encoder.fit_transform(seasonal_test['sex'])\n",
    "    \n",
    "    return h1n1_train, h1n1_test, seasonal_train, seasonal_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train, h1n1_test, seasonal_train, seasonal_test = label_encode_columns(h1n1_train, h1n1_test, seasonal_train, seasonal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train, seasonal_test = label_encode_columns(seasonal_train, seasonal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_cols = ['rent_or_own', 'employment_status', 'marital_status', 'sex']\n",
    "\n",
    "# categorical_cols\n",
    "\n",
    "# train[categorical_cols] = train[categorical_cols].apply(lambda col: encoder.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode(train, test):\n",
    "#     # creating instance of one-hot-encoder\n",
    "#     enc = OneHotEncoder()\n",
    "#     # passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "#     enc_df = pd.DataFrame(enc.fit_transform(train[['age_group', 'education', 'race', 'income_poverty']]).toarray())\n",
    "#     # merge with main df bridge_df on key values\n",
    "#     train = train.join(enc_df)\n",
    "\n",
    "#     # passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "#     enc_df2 = pd.DataFrame(enc.fit_transform(test[['age_group', 'education', 'race', 'income_poverty']]).toarray())\n",
    "#     # merge with main df bridge_df on key values\n",
    "#     test = test.join(enc_df2)\n",
    "    \n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_name = ['age_group', 'education', 'race', 'income_poverty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = encode(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the dataframe to ensure all the label encoded columns were added correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the origional columns against the encoded ones to be clear which labels correspond to eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = h1n1_train[['rent_or_own', 'encoded_rent_or_own']]\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Own == 0\n",
    "#### Rent == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "married_df = h1n1_train[['marital_status', 'encoded_marital_status']]\n",
    "married_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Married == 0\n",
    "#### Not Married == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = h1n1_train[['sex', 'encoded_sex']]\n",
    "gender_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Female == 0 \n",
    "#### Male == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encode Remaining Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode age_group column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(h1n1_train[['age_group']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['age_group_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(h1n1_train[['age_group']]).todense()\n",
    "h1n1_train = pd.concat([\n",
    "    h1n1_train,\n",
    "    pd.DataFrame(m, columns=cols, index=h1n1_train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(h1n1_test[['age_group']]).todense()\n",
    "h1n1_test = pd.concat([\n",
    "    h1n1_test,\n",
    "    pd.DataFrame(m, columns=cols, index=h1n1_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! It worked the way I wanted. Now I have a column with a 1 if the observation falls into that category and a zero if it does not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat for the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode education column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(h1n1_train[['education']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['education_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(h1n1_train[['education']]).todense()\n",
    "h1n1_train = pd.concat([\n",
    "    h1n1_train,\n",
    "    pd.DataFrame(m, columns=cols, index=h1n1_train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(h1n1_test[['education']]).todense()\n",
    "h1n1_test = pd.concat([\n",
    "    h1n1_test,\n",
    "    pd.DataFrame(m, columns=cols, index=h1n1_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode race column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(h1n1_train[['race']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['race_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(h1n1_train[['race']]).todense()\n",
    "h1n1_train = pd.concat([\n",
    "    h1n1_train,\n",
    "    pd.DataFrame(m, columns=cols, index=h1n1_train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(h1n1_test[['race']]).todense()\n",
    "h1n1_test = pd.concat([\n",
    "    h1n1_test,\n",
    "    pd.DataFrame(m, columns=cols, index=h1n1_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode income_poverty column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(h1n1_train[['income_poverty']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['income_poverty_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(h1n1_train[['income_poverty']]).todense()\n",
    "h1n1_train = pd.concat([\n",
    "    h1n1_train,\n",
    "    pd.DataFrame(m, columns=cols, index=h1n1_train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(h1n1_test[['income_poverty']]).todense()\n",
    "h1n1_test = pd.concat([\n",
    "    h1n1_test,\n",
    "    pd.DataFrame(m, columns=cols, index=h1n1_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now perform the same encoding on the seasonal_train and test dfs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode age_group column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(seasonal_train[['age_group']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['age_group_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(seasonal_train[['age_group']]).todense()\n",
    "seasonal_train = pd.concat([\n",
    "    seasonal_train,\n",
    "    pd.DataFrame(m, columns=cols, index=seasonal_train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(seasonal_test[['age_group']]).todense()\n",
    "seasonal_test = pd.concat([\n",
    "    seasonal_test,\n",
    "    pd.DataFrame(m, columns=cols, index=seasonal_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode education column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(seasonal_train[['education']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['education_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(seasonal_train[['education']]).todense()\n",
    "seasonal_train = pd.concat([\n",
    "    seasonal_train,\n",
    "    pd.DataFrame(m, columns=cols, index=seasonal_train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(seasonal_test[['education']]).todense()\n",
    "seasonal_test = pd.concat([\n",
    "    seasonal_test,\n",
    "    pd.DataFrame(m, columns=cols, index=seasonal_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode race column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(seasonal_train[['race']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['race_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(seasonal_train[['race']]).todense()\n",
    "seasonal_train = pd.concat([\n",
    "    seasonal_train,\n",
    "    pd.DataFrame(m, columns=cols, index=seasonal_train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(seasonal_test[['race']]).todense()\n",
    "seasonal_test = pd.concat([\n",
    "    seasonal_test,\n",
    "    pd.DataFrame(m, columns=cols, index=seasonal_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode income_poverty column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(seasonal_train[['income_poverty']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['income_poverty_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(seasonal_train[['income_poverty']]).todense()\n",
    "seasonal_train = pd.concat([\n",
    "    seasonal_train,\n",
    "    pd.DataFrame(m, columns=cols, index=seasonal_train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(seasonal_test[['income_poverty']]).todense()\n",
    "seasonal_test = pd.concat([\n",
    "    seasonal_test,\n",
    "    pd.DataFrame(m, columns=cols, index=seasonal_test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn these into functions and add to prepare.py. I'll just do one example here to test if it works then comment it out to make sure I don't have duplicate columns moving forward. The other functions will only be added to the .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_income_poverty(train,test):\n",
    "    # Encode income_poverty column\n",
    "\n",
    "    # Create encoder object\n",
    "    encoder = OneHotEncoder()\n",
    "\n",
    "    # Fit on the age_group column of the train df\n",
    "    encoder.fit(train[['income_poverty']])\n",
    "\n",
    "    # nice columns for display\n",
    "    cols = ['income_poverty_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "    # Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "    m = encoder.transform(train[['income_poverty']]).todense()\n",
    "    train = pd.concat([\n",
    "        train,\n",
    "        pd.DataFrame(m, columns=cols, index=train.index)\n",
    "    ], axis=1)\n",
    "\n",
    "    m = encoder.transform(test[['income_poverty']]).todense()\n",
    "    test = pd.concat([\n",
    "        test,\n",
    "        pd.DataFrame(m, columns=cols, index=test.index)\n",
    "    ], axis=1)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following columns are either opions on a scale of 1-5 or a count of number of children or adults in a household:\n",
    "  - h1n1_concern\n",
    "  - h1n1_knowledge\n",
    "  - opinion_h1n1_vacc_effective\n",
    "  - opinion_h1n1_risk\n",
    "  - opinion_h1n1_sick_from_vacc\n",
    "  - opinion_seas_vacc_effective\n",
    "  - opinion_seas_risk\n",
    "  - opinion_seas_sick_from_vac\n",
    "  - household_adults\n",
    "  - household_children\n",
    "- All other features are on a scale of 0-1. I will apply a MinMax Scaler to the above columns to get them also on a 0-1 scale to avoid weighting issues in the models to come. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler object using SKlearn's MinMax Scaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled columns to train dataframe\n",
    "h1n1_train[['h1n1_concern','h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children'\n",
    "      ]] = scaler.fit_transform(\n",
    "    h1n1_train[['h1n1_concern',\n",
    "       'h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure scaling worked appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! The MinMax Scaler was applied correctly. Now repeat this process for the test dataframe and turn these transformations into functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled columns to test dataframes\n",
    "h1n1_test[['h1n1_concern','h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children'\n",
    "      ]] = scaler.fit_transform(\n",
    "    h1n1_test[['h1n1_concern',\n",
    "       'h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled columns to train dataframe\n",
    "seasonal_train[['h1n1_concern','h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children'\n",
    "      ]] = scaler.fit_transform(\n",
    "   seasonal_train[['h1n1_concern',\n",
    "       'h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled columns to test dataframe\n",
    "seasonal_test[['h1n1_concern','h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children'\n",
    "      ]] = scaler.fit_transform(\n",
    "   seasonal_test[['h1n1_concern',\n",
    "       'h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1n1_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to add scaled columns to train, test dataframes without modifying origional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scale(train, test, scale_column_list):\n",
    "    '''\n",
    "    Takes in train and test dataframes and a list of columns to be scaled.\n",
    "    Uses the MinMaxScaler() from SKlearn and creates a dataframe of the scaled columns \n",
    "    with labeled column names.\n",
    "    Joins the scaled dataframe to the train and test dataframes.\n",
    "    Returns the transformed dataframes.\n",
    "    '''\n",
    "\n",
    "    # Create the scaler object\n",
    "    scaler = MinMaxScaler()\n",
    "    # Create labels for the scaled columns\n",
    "    column_list_scaled = [col + '_scaled' for col in scale_column_list]\n",
    "    # Apply the scaler to the columns provided to the list and then\n",
    "    # pass in the labeled column list.\n",
    "    train_scaled = pd.DataFrame(scaler.fit_transform(train[scale_column_list]), \n",
    "                                columns = column_list_scaled, \n",
    "                                index = train.index)\n",
    "    train = train.join(train_scaled, rsuffix='_scaled')\n",
    "    # Repeat the process for train dataframe\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test[scale_column_list]), \n",
    "                                columns = column_list_scaled, \n",
    "                                index = test.index)\n",
    "    test = test.join(test_scaled, rsuffix='_scaled')\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
