{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Modeling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "#Set figure size for all plots\n",
    "plt.rc(\"figure\", figsize = (16,16))\n",
    "\n",
    "#Set fontsize for titles\n",
    "plt.rc(\"font\", size=14)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to use features captured from survey data to predict how likely individuals are to receive their H1N1 and seasonal flu vaccines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, I will be predicting two probabilities:\n",
    "- h1n1_vaccine - Whether respondent received H1N1 flu vaccine.\n",
    "- seasonal_vaccine - Whether respondent received seasonal flu vaccine.\n",
    "> Both are binary variables: 0 = No; 1 = Yes. Some respondents didn't get either vaccine, others got only one, and some got both. This is formulated as a multilabel (and not multiclass) problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Aquisition\n",
    "  * Download data into local drive\n",
    "2. Prepare\n",
    "  * Read in data csv using pandas\n",
    "  * Chekck data types and null values\n",
    "  * Fill in nulls\n",
    "  * Encode appropriately\n",
    "  * Scale if needed\n",
    "3. Explore\n",
    "4. Modeling\n",
    "5. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I downloaded the data from https://www.drivendata.org/competitions/66/flu-shot-learning/data/ into the same file where this analysis is being conducted\n",
    "- Now I'll turn the data into a pandas dataframe for analysis and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the csv using pandas\n",
    "df = pd.read_csv('Flu_Shot_Learning_Predict_H1N1_and_Seasonal_Flu_Vaccines_-_Training_Features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55 - 64 Years</td>\n",
       "      <td>&lt; 12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35 - 44 Years</td>\n",
       "      <td>12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18 - 34 Years</td>\n",
       "      <td>College Graduate</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65+ Years</td>\n",
       "      <td>12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45 - 54 Years</td>\n",
       "      <td>Some College</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26702</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65+ Years</td>\n",
       "      <td>Some College</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18 - 34 Years</td>\n",
       "      <td>College Graduate</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>lzgpxyit</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fcxhlnwr</td>\n",
       "      <td>cmhcxjea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26704</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55 - 64 Years</td>\n",
       "      <td>Some College</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lzgpxyit</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18 - 34 Years</td>\n",
       "      <td>Some College</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fcxhlnwr</td>\n",
       "      <td>haliazsg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65+ Years</td>\n",
       "      <td>Some College</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>mlyzmhmf</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26707 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "respondent_id                                                            \n",
       "0                       1.0             0.0                        0.0   \n",
       "1                       3.0             2.0                        0.0   \n",
       "2                       1.0             1.0                        0.0   \n",
       "3                       1.0             1.0                        0.0   \n",
       "4                       2.0             1.0                        0.0   \n",
       "...                     ...             ...                        ...   \n",
       "26702                   2.0             0.0                        0.0   \n",
       "26703                   1.0             2.0                        0.0   \n",
       "26704                   2.0             2.0                        0.0   \n",
       "26705                   1.0             1.0                        0.0   \n",
       "26706                   0.0             0.0                        0.0   \n",
       "\n",
       "               behavioral_avoidance  behavioral_face_mask  \\\n",
       "respondent_id                                               \n",
       "0                               0.0                   0.0   \n",
       "1                               1.0                   0.0   \n",
       "2                               1.0                   0.0   \n",
       "3                               1.0                   0.0   \n",
       "4                               1.0                   0.0   \n",
       "...                             ...                   ...   \n",
       "26702                           1.0                   0.0   \n",
       "26703                           1.0                   0.0   \n",
       "26704                           1.0                   1.0   \n",
       "26705                           0.0                   0.0   \n",
       "26706                           1.0                   0.0   \n",
       "\n",
       "               behavioral_wash_hands  behavioral_large_gatherings  \\\n",
       "respondent_id                                                       \n",
       "0                                0.0                          0.0   \n",
       "1                                1.0                          0.0   \n",
       "2                                0.0                          0.0   \n",
       "3                                1.0                          1.0   \n",
       "4                                1.0                          1.0   \n",
       "...                              ...                          ...   \n",
       "26702                            0.0                          0.0   \n",
       "26703                            1.0                          0.0   \n",
       "26704                            1.0                          1.0   \n",
       "26705                            0.0                          0.0   \n",
       "26706                            0.0                          0.0   \n",
       "\n",
       "               behavioral_outside_home  behavioral_touch_face  \\\n",
       "respondent_id                                                   \n",
       "0                                  1.0                    1.0   \n",
       "1                                  1.0                    1.0   \n",
       "2                                  0.0                    0.0   \n",
       "3                                  0.0                    0.0   \n",
       "4                                  0.0                    1.0   \n",
       "...                                ...                    ...   \n",
       "26702                              1.0                    0.0   \n",
       "26703                              0.0                    0.0   \n",
       "26704                              0.0                    1.0   \n",
       "26705                              0.0                    NaN   \n",
       "26706                              0.0                    0.0   \n",
       "\n",
       "               doctor_recc_h1n1  doctor_recc_seasonal  chronic_med_condition  \\\n",
       "respondent_id                                                                  \n",
       "0                           0.0                   0.0                    0.0   \n",
       "1                           0.0                   0.0                    0.0   \n",
       "2                           NaN                   NaN                    1.0   \n",
       "3                           0.0                   1.0                    1.0   \n",
       "4                           0.0                   0.0                    0.0   \n",
       "...                         ...                   ...                    ...   \n",
       "26702                       0.0                   0.0                    0.0   \n",
       "26703                       1.0                   1.0                    0.0   \n",
       "26704                       0.0                   0.0                    0.0   \n",
       "26705                       0.0                   0.0                    0.0   \n",
       "26706                       0.0                   0.0                    0.0   \n",
       "\n",
       "               child_under_6_months  health_worker  health_insurance  \\\n",
       "respondent_id                                                          \n",
       "0                               0.0            0.0               1.0   \n",
       "1                               0.0            0.0               1.0   \n",
       "2                               0.0            0.0               NaN   \n",
       "3                               0.0            0.0               NaN   \n",
       "4                               0.0            0.0               NaN   \n",
       "...                             ...            ...               ...   \n",
       "26702                           0.0            0.0               NaN   \n",
       "26703                           0.0            1.0               1.0   \n",
       "26704                           0.0            0.0               NaN   \n",
       "26705                           0.0            0.0               0.0   \n",
       "26706                           0.0            0.0               1.0   \n",
       "\n",
       "               opinion_h1n1_vacc_effective  opinion_h1n1_risk  \\\n",
       "respondent_id                                                   \n",
       "0                                      3.0                1.0   \n",
       "1                                      5.0                4.0   \n",
       "2                                      3.0                1.0   \n",
       "3                                      3.0                3.0   \n",
       "4                                      3.0                3.0   \n",
       "...                                    ...                ...   \n",
       "26702                                  3.0                1.0   \n",
       "26703                                  4.0                2.0   \n",
       "26704                                  4.0                4.0   \n",
       "26705                                  3.0                1.0   \n",
       "26706                                  5.0                1.0   \n",
       "\n",
       "               opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
       "respondent_id                                                             \n",
       "0                                      2.0                          2.0   \n",
       "1                                      4.0                          4.0   \n",
       "2                                      1.0                          4.0   \n",
       "3                                      5.0                          5.0   \n",
       "4                                      2.0                          3.0   \n",
       "...                                    ...                          ...   \n",
       "26702                                  1.0                          5.0   \n",
       "26703                                  2.0                          5.0   \n",
       "26704                                  2.0                          5.0   \n",
       "26705                                  2.0                          2.0   \n",
       "26706                                  1.0                          5.0   \n",
       "\n",
       "               opinion_seas_risk  opinion_seas_sick_from_vacc      age_group  \\\n",
       "respondent_id                                                                  \n",
       "0                            1.0                          2.0  55 - 64 Years   \n",
       "1                            2.0                          4.0  35 - 44 Years   \n",
       "2                            1.0                          2.0  18 - 34 Years   \n",
       "3                            4.0                          1.0      65+ Years   \n",
       "4                            1.0                          4.0  45 - 54 Years   \n",
       "...                          ...                          ...            ...   \n",
       "26702                        2.0                          2.0      65+ Years   \n",
       "26703                        1.0                          1.0  18 - 34 Years   \n",
       "26704                        4.0                          2.0  55 - 64 Years   \n",
       "26705                        1.0                          2.0  18 - 34 Years   \n",
       "26706                        1.0                          1.0      65+ Years   \n",
       "\n",
       "                      education      race     sex             income_poverty  \\\n",
       "respondent_id                                                                  \n",
       "0                    < 12 Years     White  Female              Below Poverty   \n",
       "1                      12 Years     White    Male              Below Poverty   \n",
       "2              College Graduate     White    Male  <= $75,000, Above Poverty   \n",
       "3                      12 Years     White  Female              Below Poverty   \n",
       "4                  Some College     White  Female  <= $75,000, Above Poverty   \n",
       "...                         ...       ...     ...                        ...   \n",
       "26702              Some College     White  Female  <= $75,000, Above Poverty   \n",
       "26703          College Graduate     White    Male  <= $75,000, Above Poverty   \n",
       "26704              Some College     White  Female                        NaN   \n",
       "26705              Some College  Hispanic  Female  <= $75,000, Above Poverty   \n",
       "26706              Some College     White    Male  <= $75,000, Above Poverty   \n",
       "\n",
       "              marital_status rent_or_own   employment_status hhs_geo_region  \\\n",
       "respondent_id                                                                 \n",
       "0                Not Married         Own  Not in Labor Force       oxchjgsf   \n",
       "1                Not Married        Rent            Employed       bhuqouqj   \n",
       "2                Not Married         Own            Employed       qufhixun   \n",
       "3                Not Married        Rent  Not in Labor Force       lrircsnp   \n",
       "4                    Married         Own            Employed       qufhixun   \n",
       "...                      ...         ...                 ...            ...   \n",
       "26702            Not Married         Own  Not in Labor Force       qufhixun   \n",
       "26703            Not Married        Rent            Employed       lzgpxyit   \n",
       "26704            Not Married         Own                 NaN       lzgpxyit   \n",
       "26705                Married        Rent            Employed       lrircsnp   \n",
       "26706                Married         Own  Not in Labor Force       mlyzmhmf   \n",
       "\n",
       "                             census_msa  household_adults  household_children  \\\n",
       "respondent_id                                                                   \n",
       "0                               Non-MSA               0.0                 0.0   \n",
       "1              MSA, Not Principle  City               0.0                 0.0   \n",
       "2              MSA, Not Principle  City               2.0                 0.0   \n",
       "3                   MSA, Principle City               0.0                 0.0   \n",
       "4              MSA, Not Principle  City               1.0                 0.0   \n",
       "...                                 ...               ...                 ...   \n",
       "26702                           Non-MSA               0.0                 0.0   \n",
       "26703               MSA, Principle City               1.0                 0.0   \n",
       "26704          MSA, Not Principle  City               0.0                 0.0   \n",
       "26705                           Non-MSA               1.0                 0.0   \n",
       "26706               MSA, Principle City               1.0                 0.0   \n",
       "\n",
       "              employment_industry employment_occupation  \n",
       "respondent_id                                            \n",
       "0                             NaN                   NaN  \n",
       "1                        pxcmvdjn              xgwztkwe  \n",
       "2                        rucpziij              xtkaffoo  \n",
       "3                             NaN                   NaN  \n",
       "4                        wxleyezf              emcorrxb  \n",
       "...                           ...                   ...  \n",
       "26702                         NaN                   NaN  \n",
       "26703                    fcxhlnwr              cmhcxjea  \n",
       "26704                         NaN                   NaN  \n",
       "26705                    fcxhlnwr              haliazsg  \n",
       "26706                         NaN                   NaN  \n",
       "\n",
       "[26707 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable_df = pd.read_csv('Flu_Shot_Learning_Predict_H1N1_and_Seasonal_Flu_Vaccines_-_Training_Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The initial datatframe has:\n",
    "- 26,707 rows where each row is one person\n",
    "- 35 columns where each column is a feature this person has indicated on their survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more info about the datframe. We'll use .info() to see how many non-null values we have in each column and what the data types are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26707 entries, 0 to 26706\n",
      "Data columns (total 35 columns):\n",
      "h1n1_concern                   26615 non-null float64\n",
      "h1n1_knowledge                 26591 non-null float64\n",
      "behavioral_antiviral_meds      26636 non-null float64\n",
      "behavioral_avoidance           26499 non-null float64\n",
      "behavioral_face_mask           26688 non-null float64\n",
      "behavioral_wash_hands          26665 non-null float64\n",
      "behavioral_large_gatherings    26620 non-null float64\n",
      "behavioral_outside_home        26625 non-null float64\n",
      "behavioral_touch_face          26579 non-null float64\n",
      "doctor_recc_h1n1               24547 non-null float64\n",
      "doctor_recc_seasonal           24547 non-null float64\n",
      "chronic_med_condition          25736 non-null float64\n",
      "child_under_6_months           25887 non-null float64\n",
      "health_worker                  25903 non-null float64\n",
      "health_insurance               14433 non-null float64\n",
      "opinion_h1n1_vacc_effective    26316 non-null float64\n",
      "opinion_h1n1_risk              26319 non-null float64\n",
      "opinion_h1n1_sick_from_vacc    26312 non-null float64\n",
      "opinion_seas_vacc_effective    26245 non-null float64\n",
      "opinion_seas_risk              26193 non-null float64\n",
      "opinion_seas_sick_from_vacc    26170 non-null float64\n",
      "age_group                      26707 non-null object\n",
      "education                      25300 non-null object\n",
      "race                           26707 non-null object\n",
      "sex                            26707 non-null object\n",
      "income_poverty                 22284 non-null object\n",
      "marital_status                 25299 non-null object\n",
      "rent_or_own                    24665 non-null object\n",
      "employment_status              25244 non-null object\n",
      "hhs_geo_region                 26707 non-null object\n",
      "census_msa                     26707 non-null object\n",
      "household_adults               26458 non-null float64\n",
      "household_children             26458 non-null float64\n",
      "employment_industry            13377 non-null object\n",
      "employment_occupation          13237 non-null object\n",
      "dtypes: float64(23), object(12)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial thoughts for cleaning/prep\n",
    "1. Several columns will need to be one hot encoded or label encoded\n",
    "2. Nans in several columns needs to be handled\n",
    "3. May need to drop certain columns\n",
    "4. All the datatypes seem to be appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by splitting the data into train and test to avoid exploring the test data which is meant to stay unseen. Then I'll perform the same clean and prep changes to each dataframe sequentially.\n",
    "> There's enough data here to split this further into train and validate sets which will help to prevent overfitting by allowing signs of overfitting to be caught before applying the model to the test data. After the appropriate cleaning and preparation are complete, I will create a validate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'h1n1_vaccine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2f6290ebe38b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use the train test split function from Sklearn and add a random seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh1n1_vaccine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'h1n1_vaccine'"
     ]
    }
   ],
   "source": [
    "# use the train test split function from Sklearn and add a random seed for reproducibility\n",
    "train, test = train_test_split(df, random_state=123, train_size=.80, stratify=df.h1n1_vaccine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll check to see which columns have nans, how many there are, and explore the best ways to fill those nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a for loop to determine what percentage of each column are nans\n",
    "def percent_nans(df):\n",
    "    x = ['column','n_nans', 'percentage_nans']\n",
    "    missing_data_df = pd.DataFrame(columns=x)\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        column_name = col\n",
    "        missing_data = df[col].isnull().sum()\n",
    "        missing_in_percentage = (df[col].isnull().sum()/df[col].shape[0])*100\n",
    "        \n",
    "        missing_data_df.loc[len(missing_data_df)] = [column_name, missing_data, missing_in_percentage]\n",
    "    return missing_data_df.sort_values(by = 'percentage_nans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_nans(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like only three columns have a significant number of values missing:\n",
    "  - __health_insurance__\n",
    "  - __employment_industry__\n",
    "  - __employment_occupation__\n",
    "- Look at the most common values in each feature and decide if there is a reasonable way to fill the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the most common health insurance?\n",
    "df.health_insurance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the most common employment_industry?\n",
    "df.employment_industry.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the most common employment occupation?\n",
    "df.employment_occupation.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that __employment_industry__ and __employment_occupation__ do not have a single most overwhelming industry or occupation that could be reasonably used to fill in the remaining half empty values. I will drop these columns and not include them in the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, __health_insurance__ has 12,697 observation recoded as having insurance of the total 14,433 observations with values recorded. It may be reasonable to simply fill in the remaining 45% missing values with the label for having insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the employment_industry and employment_occupation columns from dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns =['employment_industry', 'employment_occupation'] )\n",
    "test = test.drop(columns =['employment_industry', 'employment_occupation'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure the columns were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the columns were dropped appropriately. Now let's fill in null values in the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to fill in the null values with the most common occurence\n",
    "def fill_null_values(train, test):\n",
    "    train = train.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "    test = test.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = fill_null_values(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that there are no more null values in either dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to encode the columns that have objects as values and turn them into integer representations for the purpose of the classification model to predict how likely people are to get their flu vaccines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at which columns need to be encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label_encode_columns(train, test):\n",
    "\n",
    "#     encoder = LabelEncoder()\n",
    "   \n",
    "#     encode_list = ['rent_or_own', 'employment_status', 'marital_status', 'sex']\n",
    "    \n",
    "             \n",
    "#     for column in encode_list:\n",
    "#         train[column] = encoder.fit_transform(train[column])\n",
    "#         test[column] = encoder.transform(test[column])\n",
    "\n",
    "#         return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = label_encode_columns(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_columns(train, test):\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "   \n",
    "    train['encoded_rent_or_own'] = encoder.fit_transform(train['rent_or_own'])\n",
    "    train['encoded_marital_status'] = encoder.fit_transform(train['marital_status'])\n",
    "    train['encoded_sex'] = encoder.fit_transform(train['sex'])\n",
    "\n",
    "    test['encoded_rent_or_own'] = encoder.fit_transform(test['rent_or_own'])\n",
    "    test['encoded_marital_status'] = encoder.fit_transform(test['marital_status'])\n",
    "    test['encoded_sex'] = encoder.fit_transform(test['sex'])\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = label_encode_columns(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_cols = ['rent_or_own', 'employment_status', 'marital_status', 'sex']\n",
    "\n",
    "# categorical_cols\n",
    "\n",
    "# train[categorical_cols] = train[categorical_cols].apply(lambda col: encoder.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode(train, test):\n",
    "#     # creating instance of one-hot-encoder\n",
    "#     enc = OneHotEncoder()\n",
    "#     # passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "#     enc_df = pd.DataFrame(enc.fit_transform(train[['age_group', 'education', 'race', 'income_poverty']]).toarray())\n",
    "#     # merge with main df bridge_df on key values\n",
    "#     train = train.join(enc_df)\n",
    "\n",
    "#     # passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "#     enc_df2 = pd.DataFrame(enc.fit_transform(test[['age_group', 'education', 'race', 'income_poverty']]).toarray())\n",
    "#     # merge with main df bridge_df on key values\n",
    "#     test = test.join(enc_df2)\n",
    "    \n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_name = ['age_group', 'education', 'race', 'income_poverty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = encode(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the dataframe to ensure all the label encoded columns were added correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the origional columns against the encoded ones to be clear which labels correspond to eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = train[['rent_or_own', 'encoded_rent_or_own']]\n",
    "housing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Own == 0\n",
    "#### Rent == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "married_df = train[['marital_status', 'encoded_marital_status']]\n",
    "married_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Married == 0\n",
    "#### Not Married == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = train[['sex', 'encoded_sex']]\n",
    "gender_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Female == 0 \n",
    "#### Male == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encode Remaining Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode age_group column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(train[['age_group']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['age_group_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(train[['age_group']]).todense()\n",
    "train = pd.concat([\n",
    "    train,\n",
    "    pd.DataFrame(m, columns=cols, index=train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(test[['age_group']]).todense()\n",
    "test = pd.concat([\n",
    "    test,\n",
    "    pd.DataFrame(m, columns=cols, index=test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! It worked the way I wanted. Now I have a column with a 1 if the observation falls into that category and a zero if it does not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat for the remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode education column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(train[['education']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['education_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(train[['education']]).todense()\n",
    "train = pd.concat([\n",
    "    train,\n",
    "    pd.DataFrame(m, columns=cols, index=train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(test[['education']]).todense()\n",
    "test = pd.concat([\n",
    "    test,\n",
    "    pd.DataFrame(m, columns=cols, index=test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode race column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(train[['race']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['race_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(train[['race']]).todense()\n",
    "train = pd.concat([\n",
    "    train,\n",
    "    pd.DataFrame(m, columns=cols, index=train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(test[['race']]).todense()\n",
    "test = pd.concat([\n",
    "    test,\n",
    "    pd.DataFrame(m, columns=cols, index=test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode income_poverty column\n",
    "\n",
    "# Create encoder object\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit on the age_group column of the train df\n",
    "encoder.fit(train[['income_poverty']])\n",
    "\n",
    "# nice columns for display\n",
    "cols = ['income_poverty_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "# Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "m = encoder.transform(train[['income_poverty']]).todense()\n",
    "train = pd.concat([\n",
    "    train,\n",
    "    pd.DataFrame(m, columns=cols, index=train.index)\n",
    "], axis=1)\n",
    "\n",
    "m = encoder.transform(test[['income_poverty']]).todense()\n",
    "test = pd.concat([\n",
    "    test,\n",
    "    pd.DataFrame(m, columns=cols, index=test.index)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn these into functions and add to prepare.py. I'll just do one example here to test if it works then comment it out to make sure I don't have duplicate columns moving forward. The other functions will only be added to the .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ohe_income_poverty(train,test):\n",
    "#     # Encode income_poverty column\n",
    "\n",
    "#     # Create encoder object\n",
    "#     encoder = OneHotEncoder()\n",
    "\n",
    "#     # Fit on the age_group column of the train df\n",
    "#     encoder.fit(train[['income_poverty']])\n",
    "\n",
    "#     # nice columns for display\n",
    "#     cols = ['income_poverty_' + c for c in encoder.categories_[0]]\n",
    "\n",
    "#     # Transform the column on train and test and concatenate new df onto train and test dfs\n",
    "#     m = encoder.transform(train[['income_poverty']]).todense()\n",
    "#     train = pd.concat([\n",
    "#         train,\n",
    "#         pd.DataFrame(m, columns=cols, index=train.index)\n",
    "#     ], axis=1)\n",
    "\n",
    "#     m = encoder.transform(test[['income_poverty']]).todense()\n",
    "#     test = pd.concat([\n",
    "#         test,\n",
    "#         pd.DataFrame(m, columns=cols, index=test.index)\n",
    "#     ], axis=1)\n",
    "\n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following columns are either opions on a scale of 1-5 or a count of number of children or adults in a household:\n",
    "  - h1n1_concern\n",
    "  - h1n1_knowledge\n",
    "  - opinion_h1n1_vacc_effective\n",
    "  - opinion_h1n1_risk\n",
    "  - opinion_h1n1_sick_from_vacc\n",
    "  - opinion_seas_vacc_effective\n",
    "  - opinion_seas_risk\n",
    "  - opinion_seas_sick_from_vac\n",
    "  - household_adults\n",
    "  - household_children\n",
    "- All other features are on a scale of 0-1. I will apply a MinMax Scaler to the above columns to get them also on a 0-1 scale to avoid weighting issues in the models to come. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler object using SKlearn's MinMax Scaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled columns to train dataframe\n",
    "train[['h1n1_concern','h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children'\n",
    "      ]] = scaler.fit_transform(\n",
    "    train[['h1n1_concern',\n",
    "       'h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure scaling worked appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! The MinMax Scaler was applied correctly. Now repeat this process for the test dataframe and turn these transformations into functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled columns to train and test dataframes\n",
    "test[['h1n1_concern','h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children'\n",
    "      ]] = scaler.fit_transform(\n",
    "    test[['h1n1_concern',\n",
    "       'h1n1_knowledge', \n",
    "       'opinion_h1n1_vacc_effective',\n",
    "       'opinion_h1n1_risk',\n",
    "       'opinion_h1n1_sick_from_vacc',\n",
    "       'opinion_seas_vacc_effective',\n",
    "       'opinion_seas_risk',\n",
    "       'opinion_seas_sick_from_vacc',\n",
    "       'household_adults',\n",
    "       'household_children']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
